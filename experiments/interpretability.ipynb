{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f5b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Final X shape: (100000, 7, 7)\n",
      "Pre-processing training and test dataset\n",
      "[[1 2 0 1 0 0 1]\n",
      " [2 1 1 1 0 1 2]\n",
      " [2 1 0 1 2 2 2]\n",
      " [2 1 2 0 1 1 2]\n",
      " [2 2 1 0 0 2 1]\n",
      " [1 1 0 2 2 1 2]\n",
      " [2 2 2 1 0 0 1]]\n",
      "Winner label: 1\n"
     ]
    }
   ],
   "source": [
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "\n",
    "from src.utils.x_builder import build_boards_from_moves\n",
    "from src.utils.utils import transform_dataset, build_symbol_list, boards_to_games_dict, build_hex_adjacency, build_graphs\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "\n",
    "epochs = 15\n",
    "clauses = 5000\n",
    "T = 3250\n",
    "s = 1.15\n",
    "depth = 2\n",
    "hv_bits = 1\n",
    "hv_size = 1\n",
    "msg_bits = 32\n",
    "msg_size = 512\n",
    "board_size = 7\n",
    "n_board = board_size ** 2\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = np.load(\"dataset/hex_7x7_100000.npz\")\n",
    "moves = dataset[\"moves\"]\n",
    "lengths = dataset[\"lengths\"]\n",
    "y_ds = dataset[\"winners\"]\n",
    "x_ds = build_boards_from_moves(moves, lengths, offset=0)\n",
    "\n",
    "print(\"Final X shape:\", x_ds.shape)\n",
    "\n",
    "print(\"Pre-processing training and test dataset\")\n",
    "# Split 80% train / 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_ds, y_ds, test_size=0.2, random_state=42\n",
    ")\n",
    "game = 19999\n",
    "print(X_train[game])\n",
    "\n",
    "#print(\"Transforming dataset\")\n",
    "X_train = transform_dataset(X_train)\n",
    "X_test = transform_dataset(X_test)\n",
    "#print(f\"Transformed dataset to {X_test[game]}\")\n",
    "print(f\"Winner label: {y_train[game]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f26ba00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting board to game disctionaries\n",
      "Creating nodes and edges\n",
      "Creating symbols\n",
      "Train has 118 symbols\n",
      "Preparing node configuration for Train\n",
      "Preparing edge configuration for Train\n",
      "Adding Train node properties\n",
      "Test has 118 symbols\n",
      "Preparing node configuration for Test\n",
      "Preparing edge configuration for Test\n",
      "Adding Test node properties\n",
      "Initialization of sparse structure.\n",
      "Starting training...\n",
      "Epoch: 1, Train acc: 73.18%, Test acc: 73.16%, Training time: 52.02s, Inference time: 7.64s\n",
      "Epoch: 2, Train acc: 83.50%, Test acc: 82.98%, Training time: 46.86s, Inference time: 7.62s\n",
      "Epoch: 3, Train acc: 85.86%, Test acc: 85.06%, Training time: 45.14s, Inference time: 7.43s\n",
      "Epoch: 4, Train acc: 85.61%, Test acc: 85.00%, Training time: 43.76s, Inference time: 7.29s\n",
      "Epoch: 5, Train acc: 87.84%, Test acc: 87.31%, Training time: 43.04s, Inference time: 7.17s\n",
      "Epoch: 6, Train acc: 87.64%, Test acc: 87.30%, Training time: 42.38s, Inference time: 7.45s\n",
      "Epoch: 7, Train acc: 91.86%, Test acc: 91.36%, Training time: 41.82s, Inference time: 7.43s\n",
      "Epoch: 8, Train acc: 90.03%, Test acc: 89.48%, Training time: 41.41s, Inference time: 7.28s\n",
      "Epoch: 9, Train acc: 92.84%, Test acc: 92.47%, Training time: 40.93s, Inference time: 7.32s\n",
      "Epoch: 10, Train acc: 95.86%, Test acc: 95.59%, Training time: 40.15s, Inference time: 7.10s\n",
      "Epoch: 11, Train acc: 96.87%, Test acc: 96.52%, Training time: 39.57s, Inference time: 7.12s\n",
      "Epoch: 12, Train acc: 96.13%, Test acc: 95.91%, Training time: 39.35s, Inference time: 6.97s\n",
      "Epoch: 13, Train acc: 97.08%, Test acc: 96.80%, Training time: 38.85s, Inference time: 7.06s\n",
      "Epoch: 14, Train acc: 96.00%, Test acc: 95.76%, Training time: 38.74s, Inference time: 7.21s\n",
      "Epoch: 15, Train acc: 98.22%, Test acc: 98.02%, Training time: 38.66s, Inference time: 7.19s\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype(np.uint32)\n",
    "y_test = y_test.astype(np.uint32)\n",
    "\n",
    "train_graph_length = X_train.shape[0]\n",
    "test_graph_length = X_test.shape[0] \n",
    "\n",
    "print(\"Converting board to game disctionaries\")\n",
    "train_games = boards_to_games_dict(X_train, board_size)\n",
    "test_games = boards_to_games_dict(X_test, board_size)\n",
    "\n",
    "print(\"Creating nodes and edges\")\n",
    "edges = build_hex_adjacency(board_size)\n",
    "\n",
    "print(\"Creating symbols\")\n",
    "symbols = build_symbol_list(board_size)\n",
    "edge_symbols = [\"Plain\", \"Player 1\", \"Player 2\"]\n",
    "symbols.extend(edge_symbols)\n",
    "hv_size = len(symbols)\n",
    "graphs_train = build_graphs(\"Train\", X=X_train, games=train_games, symbols=symbols, edges=edges, board_size=board_size,hv_size=hv_size, hv_bits=hv_bits)\n",
    "graphs_test = build_graphs(\"Test\", graphs_train, X_test, test_games, symbols, edges, board_size, hv_size, hv_bits)\n",
    "\n",
    "tm = MultiClassGraphTsetlinMachine(\n",
    "    clauses,\n",
    "    T,\n",
    "    s,\n",
    "    depth=depth,\n",
    "    message_size=msg_size,\n",
    "    message_bits=msg_bits,\n",
    "    grid=(16*13,1,1),\n",
    "    block=(128,1,1),\n",
    "    #double_hashing=True,\n",
    "    #one_hot_encoding=True\n",
    ")\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "epoch_list = []\n",
    "epoch = 0\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for i in range(epochs):\n",
    "    epoch += 1\n",
    "\n",
    "    start_training = time()\n",
    "    tm.fit(graphs_train, y_train, epochs=1, incremental=True)\n",
    "    stop_training = time()\n",
    "    training_time = stop_training - start_training\n",
    "\n",
    "    start_testing = time()\n",
    "    result_test = 100.0 * (tm.predict(graphs_test) == y_test).mean()\n",
    "    stop_testing = time()\n",
    "    inference_time = stop_testing - start_testing\n",
    "\n",
    "    result_train = 100.0 * (tm.predict(graphs_train) == y_train).mean()\n",
    "\n",
    "    train_acc.append(result_train)\n",
    "    test_acc.append(result_test)\n",
    "    epoch_list.append(epoch)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, \"\n",
    "        f\"Train acc: {result_train:.2f}%, \"\n",
    "        f\"Test acc: {result_test:.2f}%, \"\n",
    "        f\"Training time: {training_time:.2f}s, \"\n",
    "        f\"Inference time: {inference_time:.2f}s\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007895c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Interpretability analysis on one test game ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Interpretability analysis on one test game ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    104\u001b[39m g_idx = \u001b[32m0\u001b[39m  \u001b[38;5;66;03m# choose which test game to inspect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m (\n\u001b[32m    107\u001b[39m     pred_class,\n\u001b[32m    108\u001b[39m     pos_map,\n\u001b[32m    109\u001b[39m     neg_map,\n\u001b[32m    110\u001b[39m     active_clauses,\n\u001b[32m    111\u001b[39m     board_node_scores,\n\u001b[32m    112\u001b[39m     virtual_node_scores,\n\u001b[32m    113\u001b[39m ) = explain_hex_game(\n\u001b[32m    114\u001b[39m     game_idx=g_idx,\n\u001b[32m    115\u001b[39m     graphs=graphs_test,\n\u001b[32m    116\u001b[39m     tm=tm,\n\u001b[32m    117\u001b[39m     symbols=symbols,\n\u001b[32m    118\u001b[39m     board_size=board_size,\n\u001b[32m    119\u001b[39m )\n\u001b[32m    121\u001b[39m \u001b[38;5;28mprint\u001b[39m(X_test[g_idx])\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredicted winner (class):\u001b[39m\u001b[33m\"\u001b[39m, pred_class)\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 6)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def parse_cell_symbol(sym_name: str):\n",
    "    if sym_name.startswith(\"Placement_\"):\n",
    "        _, i, j = sym_name.split(\"_\")\n",
    "        return int(i), int(j)\n",
    "\n",
    "    if sym_name.startswith(\"Connected_\"):\n",
    "        _, i, j = sym_name.split(\"_\")\n",
    "        return int(i), int(j)\n",
    "    return None\n",
    "\n",
    "\n",
    "def explain_hex_game(game_idx, graphs, tm, symbols, board_size: int):\n",
    "\n",
    "    symbol_hv = graphs.hypervectors\n",
    "    clause_literals = tm.get_clause_literals(symbol_hv)  # (n_clauses, 2*n_symbols)\n",
    "    n_symbols = symbol_hv.shape[0]\n",
    "\n",
    "    # 2) Nodewise clause activations for all graphs\n",
    "    clause_node_output, class_sum = tm.transform_nodewise(graphs)\n",
    "    # clause_node_output: (n_graphs, n_clauses, max_nodes)\n",
    "\n",
    "    clause_node = clause_node_output[game_idx]          # (n_clauses, n_nodes)\n",
    "    pred_class = int(np.argmax(class_sum[game_idx]))    # predicted winner for this game\n",
    "\n",
    "    # 3) Restrict to clauses of the predicted class\n",
    "    n_total_clauses = tm.number_of_clauses\n",
    "    n_outputs = tm.number_of_outputs\n",
    "    clauses_per_class = n_total_clauses // n_outputs\n",
    "\n",
    "    class_start = pred_class * clauses_per_class\n",
    "    class_end = (pred_class + 1) * clauses_per_class\n",
    "\n",
    "    # Clauses that fired on at least one node in THIS game\n",
    "    firing = np.where(clause_node.sum(axis=1) > 0)[0]\n",
    "    active_clauses = firing[(firing >= class_start) & (firing < class_end)]\n",
    "\n",
    "    # 4) Aggregate which symbols those active clauses actually use\n",
    "    pos_part = clause_literals[active_clauses, :n_symbols]\n",
    "    neg_part = clause_literals[active_clauses, n_symbols:]\n",
    "\n",
    "    # For each symbol: how many active clauses include it\n",
    "    pos_sym_scores = (pos_part > 0).sum(axis=0)\n",
    "    neg_sym_scores = (neg_part > 0).sum(axis=0)\n",
    "\n",
    "    # 5) Map symbol scores back to board coordinates\n",
    "    board_pos = np.zeros((board_size, board_size), dtype=float)\n",
    "    board_neg = np.zeros_like(board_pos)\n",
    "\n",
    "    for s_id, sym in enumerate(symbols):\n",
    "        parsed = parse_cell_symbol(sym)\n",
    "        if parsed is None:\n",
    "            continue\n",
    "        i, j = parsed\n",
    "        board_pos[i, j] += pos_sym_scores[s_id]\n",
    "        board_neg[i, j] += neg_sym_scores[s_id]\n",
    "\n",
    "    return pred_class, board_pos, board_neg, active_clauses\n",
    "\n",
    "print(\"\\n=== Interpretability analysis on one test game ===\")\n",
    "g_idx = 0  \n",
    "\n",
    "pred_class, pos_map, neg_map, active_clauses = explain_hex_game(\n",
    "    game_idx=g_idx,\n",
    "    graphs=graphs_test,\n",
    "    tm=tm,\n",
    "    symbols=symbols,\n",
    "    board_size=board_size,\n",
    ")\n",
    "print(X_test[g_idx])\n",
    "print(\"Predicted winner (class):\", pred_class)\n",
    "print(\"Actual winner: \", y_test[g_idx])\n",
    "print(\"Positive evidence heatmap:\\n\", pos_map)\n",
    "print(\"Negative (negated) evidence heatmap:\\n\", neg_map)\n",
    "print(\"Number of active clauses for this game:\", len(active_clauses))\n",
    "board = X_test[g_idx]  # shape (board_size, board_size)\n",
    "\n",
    "# 0=empty, 1=Player1, 2=Player2\n",
    "cmap_board = ListedColormap([\"white\", \"black\", \"gray\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(9, 3))\n",
    "\n",
    "axes[0].imshow(board, cmap=cmap_board, vmin=0, vmax=2, interpolation=\"nearest\")\n",
    "axes[0].set_title(f\"Board (game {g_idx})\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(pos_map, cmap=\"Reds\", interpolation=\"nearest\")\n",
    "axes[1].set_title(\"Positive literals\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(neg_map, cmap=\"Blues\", interpolation=\"nearest\")\n",
    "axes[2].set_title(\"Negated literals\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
